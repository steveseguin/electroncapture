<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Automated Capture Test</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: #1a1a2e;
      color: #eee;
      margin: 0;
      padding: 20px;
      min-height: 100vh;
    }
    h1 { color: #00d4ff; margin-bottom: 5px; }
    .subtitle { color: #888; margin-bottom: 20px; }
    .container { max-width: 1200px; margin: 0 auto; }
    .status-panel {
      background: #16213e;
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
    }
    .test-row {
      display: flex;
      align-items: center;
      padding: 10px 0;
      border-bottom: 1px solid #2a2a4a;
    }
    .test-row:last-child { border-bottom: none; }
    .test-name { flex: 1; font-weight: 500; }
    .test-status {
      padding: 4px 12px;
      border-radius: 4px;
      font-size: 12px;
      font-weight: bold;
      text-transform: uppercase;
    }
    .test-status.pending { background: #444; color: #888; }
    .test-status.running { background: #0066cc; color: #fff; }
    .test-status.pass { background: #00aa44; color: #fff; }
    .test-status.fail { background: #cc3333; color: #fff; }
    .test-detail { color: #888; font-size: 12px; margin-left: 10px; min-width: 200px; text-align: right; }
    .preview-section {
      display: flex;
      gap: 20px;
      margin-bottom: 20px;
    }
    .preview-box {
      flex: 1;
      background: #16213e;
      border-radius: 8px;
      padding: 15px;
    }
    .preview-box h3 { margin: 0 0 10px 0; color: #00d4ff; font-size: 14px; }
    video {
      width: 100%;
      background: #000;
      border-radius: 4px;
    }
    .audio-meter {
      height: 20px;
      background: #111;
      border-radius: 4px;
      overflow: hidden;
      margin-top: 10px;
    }
    .audio-meter-fill {
      height: 100%;
      background: linear-gradient(90deg, #00aa44, #ffaa00, #cc3333);
      width: 0%;
      transition: width 100ms;
    }
    .overall-result {
      text-align: center;
      font-size: 32px;
      font-weight: bold;
      padding: 30px;
      border-radius: 8px;
      margin-top: 20px;
    }
    .overall-result.pass { background: #00aa44; }
    .overall-result.fail { background: #cc3333; }
    .overall-result.running { background: #0066cc; }
    .log-panel {
      background: #111;
      border-radius: 8px;
      padding: 15px;
      font-family: monospace;
      font-size: 12px;
      max-height: 200px;
      overflow-y: auto;
      margin-top: 20px;
    }
    .log-entry { margin: 2px 0; }
    .log-entry.error { color: #ff6666; }
    .log-entry.success { color: #66ff66; }
    .log-entry.info { color: #6699ff; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Automated Window Audio Capture Test</h1>
    <p class="subtitle">Testing window-audio-capture library with Electron v39.2.7-qp20</p>

    <div class="preview-section">
      <div class="preview-box">
        <h3>Captured Video (Edge Window)</h3>
        <video id="localVideo" autoplay muted playsinline></video>
      </div>
      <div class="preview-box">
        <h3>WebRTC Loopback (Received)</h3>
        <video id="remoteVideo" autoplay muted playsinline></video>
      </div>
    </div>

    <div class="preview-box" style="margin-bottom: 20px;">
      <h3>Audio Level (Captured from Edge)</h3>
      <div class="audio-meter">
        <div class="audio-meter-fill" id="audioMeter"></div>
      </div>
      <div style="display: flex; justify-content: space-between; font-size: 11px; color: #666; margin-top: 5px;">
        <span>-60 dB</span>
        <span id="audioLevelText">-- dB</span>
        <span>0 dB</span>
      </div>
    </div>

    <div class="status-panel">
      <div class="test-row">
        <span class="test-name">1. Edge Window Discovery</span>
        <span class="test-status pending" id="test1-status">PENDING</span>
        <span class="test-detail" id="test1-detail">--</span>
      </div>
      <div class="test-row">
        <span class="test-name">2. Video Capture</span>
        <span class="test-status pending" id="test2-status">PENDING</span>
        <span class="test-detail" id="test2-detail">--</span>
      </div>
      <div class="test-row">
        <span class="test-name">3. Audio Session Discovery</span>
        <span class="test-status pending" id="test3-status">PENDING</span>
        <span class="test-detail" id="test3-detail">--</span>
      </div>
      <div class="test-row">
        <span class="test-name">4. Audio Capture (Native Module)</span>
        <span class="test-status pending" id="test4-status">PENDING</span>
        <span class="test-detail" id="test4-detail">--</span>
      </div>
      <div class="test-row">
        <span class="test-name">5. Audio Level Detection</span>
        <span class="test-status pending" id="test5-status">PENDING</span>
        <span class="test-detail" id="test5-detail">--</span>
      </div>
      <div class="test-row">
        <span class="test-name">6. WebRTC Video Loopback</span>
        <span class="test-status pending" id="test6-status">PENDING</span>
        <span class="test-detail" id="test6-detail">--</span>
      </div>
      <div class="test-row">
        <span class="test-name">7. WebRTC Audio Loopback</span>
        <span class="test-status pending" id="test7-status">PENDING</span>
        <span class="test-detail" id="test7-detail">--</span>
      </div>
    </div>

    <div class="overall-result running" id="overallResult">RUNNING TESTS...</div>

    <div class="log-panel" id="logPanel"></div>
  </div>

  <script>
    // Test state
    const testResults = {
      edgeWindowFound: false,
      videoCaptureWorking: false,
      audioSessionFound: false,
      audioCaptureWorking: false,
      audioLevelDetected: false,
      webrtcVideoWorking: false,
      webrtcAudioWorking: false
    };

    let localPc, remotePc;
    let audioAnalyser, audioDataArray;
    let maxAudioLevel = -Infinity;
    let audioSampleCount = 0;

    // Get ipcRenderer for logging to main process
    let ipcRenderer;
    try {
      ipcRenderer = require('electron').ipcRenderer;
    } catch (e) {
      console.error('Failed to load ipcRenderer:', e);
    }

    // Logging - also sends to main process for terminal visibility
    function log(msg, type = 'info') {
      const formattedMsg = `[TEST:${type.toUpperCase()}] ${msg}`;
      console.log(formattedMsg);
      // Send to main process so it appears in terminal
      if (ipcRenderer) {
        ipcRenderer.send('test-log', { type, msg });
      }
      const panel = document.getElementById('logPanel');
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      entry.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
      panel.appendChild(entry);
      panel.scrollTop = panel.scrollHeight;
    }

    // Update test status
    function setTestStatus(testNum, status, detail = '') {
      const statusEl = document.getElementById(`test${testNum}-status`);
      const detailEl = document.getElementById(`test${testNum}-detail`);
      statusEl.textContent = status.toUpperCase();
      statusEl.className = `test-status ${status}`;
      if (detail) detailEl.textContent = detail;
    }

    // Calculate RMS level in dB
    function calculateRmsDb(dataArray) {
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        const normalized = (dataArray[i] - 128) / 128;
        sum += normalized * normalized;
      }
      const rms = Math.sqrt(sum / dataArray.length);
      return 20 * Math.log10(Math.max(rms, 0.0001));
    }

    // Main test function
    async function runTests() {
      log('Starting automated capture tests...', 'info');

      try {
        // =====================================================
        // TEST 1: Find Edge Window via desktopCapturer
        // =====================================================
        setTestStatus(1, 'running');
        log('Searching for Edge window...');

        // Use synchronous IPC to get sources (main.js has getSources handler)
        const { ipcRenderer } = require('electron');
        const sources = ipcRenderer.sendSync('getSources', { types: ['window', 'screen'] });

        if (!sources || sources.length === 0) {
          throw new Error('No desktop sources found');
        }

        log(`Found ${sources.length} sources`);
        sources.forEach((s, i) => log(`  [${i}] ${s.name}`));

        const edgeSource = sources.find(s =>
          s.name.toLowerCase().includes('edge') ||
          s.name.toLowerCase().includes('microsoft edge')
        );

        if (!edgeSource) {
          setTestStatus(1, 'fail', 'Edge window not found');
          throw new Error('Edge window not found. Please open Edge with audio playing.');
        }

        testResults.edgeWindowFound = true;
        setTestStatus(1, 'pass', `Found: ${edgeSource.name.substring(0, 30)}...`);
        log(`Found Edge window: ${edgeSource.name}`, 'success');

        // =====================================================
        // TEST 2: Capture Edge Video
        // =====================================================
        setTestStatus(2, 'running');
        log('Starting video capture...');

        const videoStream = await navigator.mediaDevices.getUserMedia({
          audio: false,
          video: {
            mandatory: {
              chromeMediaSource: 'desktop',
              chromeMediaSourceId: edgeSource.id,
              maxWidth: 1920,
              maxHeight: 1080
            }
          }
        });

        const videoTrack = videoStream.getVideoTracks()[0];
        if (!videoTrack || videoTrack.readyState !== 'live') {
          setTestStatus(2, 'fail', 'Video track not live');
          throw new Error('Video capture failed - track not live');
        }

        document.getElementById('localVideo').srcObject = videoStream;
        testResults.videoCaptureWorking = true;
        setTestStatus(2, 'pass', `Track: ${videoTrack.label.substring(0, 25)}...`);
        log('Video capture successful', 'success');

        // =====================================================
        // TEST 3: Find Edge Audio Session
        // =====================================================
        setTestStatus(3, 'running');
        log('Searching for Edge audio session...');

        if (!window.electronApi || !window.electronApi.getWindowAudioSessions) {
          setTestStatus(3, 'fail', 'electronApi not available');
          throw new Error('electronApi.getWindowAudioSessions not available');
        }

        const sessionsResult = await window.electronApi.getWindowAudioSessions();
        if (!sessionsResult || !sessionsResult.success) {
          setTestStatus(3, 'fail', sessionsResult?.error || 'API failed');
          throw new Error(sessionsResult?.error || 'Failed to get audio sessions');
        }
        const sessions = sessionsResult.sessions || [];
        log(`Found ${sessions.length} audio sessions`);
        sessions.forEach((s, i) => log(`  [${i}] PID:${s.processId} ${s.executableName || s.displayName || 'unknown'}`));

        const edgeSession = sessions.find(s =>
          (s.executableName && s.executableName.toLowerCase().includes('msedge')) ||
          (s.displayName && s.displayName.toLowerCase().includes('edge'))
        );

        if (!edgeSession) {
          setTestStatus(3, 'fail', 'Edge audio session not found');
          throw new Error('Edge audio session not found. Is Edge playing audio?');
        }

        testResults.audioSessionFound = true;
        setTestStatus(3, 'pass', `PID: ${edgeSession.processId}`);
        log(`Found Edge audio session: PID ${edgeSession.processId}`, 'success');

        // =====================================================
        // TEST 4: Start Audio Capture via WindowAudioStream
        // =====================================================
        setTestStatus(4, 'running');
        log('Starting audio capture...');

        if (!window.WindowAudioStream) {
          setTestStatus(4, 'fail', 'WindowAudioStream not available');
          throw new Error('WindowAudioStream class not available');
        }

        const windowAudio = new window.WindowAudioStream();
        const audioStream = await windowAudio.start(edgeSession.processId);

        if (!audioStream) {
          setTestStatus(4, 'fail', 'No audio stream returned');
          throw new Error('WindowAudioStream.start() returned no stream');
        }

        const audioTrack = audioStream.getAudioTracks()[0];
        if (!audioTrack || audioTrack.readyState !== 'live') {
          setTestStatus(4, 'fail', 'Audio track not live');
          throw new Error('Audio track not live');
        }

        testResults.audioCaptureWorking = true;
        setTestStatus(4, 'pass', `Capturing PID ${edgeSession.processId}`);
        log('Audio capture started successfully', 'success');

        // =====================================================
        // TEST 5: Detect Audio Level
        // =====================================================
        setTestStatus(5, 'running');
        log('Analyzing audio levels...');

        const audioCtx = new AudioContext();
        const source = audioCtx.createMediaStreamSource(audioStream);
        audioAnalyser = audioCtx.createAnalyser();
        audioAnalyser.fftSize = 256;
        source.connect(audioAnalyser);
        audioDataArray = new Uint8Array(audioAnalyser.frequencyBinCount);

        // Monitor audio level for 3 seconds
        const audioLevelPromise = new Promise((resolve) => {
          const startTime = Date.now();
          const checkLevel = () => {
            audioAnalyser.getByteTimeDomainData(audioDataArray);
            const rmsDb = calculateRmsDb(audioDataArray);

            if (rmsDb > maxAudioLevel) {
              maxAudioLevel = rmsDb;
            }

            // Update meter
            const meterPercent = Math.max(0, Math.min(100, ((rmsDb + 60) / 60) * 100));
            document.getElementById('audioMeter').style.width = meterPercent + '%';
            document.getElementById('audioLevelText').textContent = rmsDb.toFixed(1) + ' dB';

            if (Date.now() - startTime < 3000) {
              requestAnimationFrame(checkLevel);
            } else {
              resolve(maxAudioLevel);
            }
          };
          checkLevel();
        });

        const finalLevel = await audioLevelPromise;

        if (finalLevel > -55) { // Expect some audio signal
          testResults.audioLevelDetected = true;
          setTestStatus(5, 'pass', `Peak: ${finalLevel.toFixed(1)} dB`);
          log(`Audio level detected: ${finalLevel.toFixed(1)} dB`, 'success');
        } else {
          setTestStatus(5, 'fail', `Too quiet: ${finalLevel.toFixed(1)} dB`);
          log(`Audio too quiet: ${finalLevel.toFixed(1)} dB (expected > -55 dB)`, 'error');
        }

        // =====================================================
        // TEST 6 & 7: WebRTC Loopback
        // =====================================================
        setTestStatus(6, 'running');
        setTestStatus(7, 'running');
        log('Setting up WebRTC loopback...');

        // Combine video and audio into one stream
        const combinedStream = new MediaStream([
          ...videoStream.getVideoTracks(),
          ...audioStream.getAudioTracks()
        ]);

        // Create peer connections
        localPc = new RTCPeerConnection();
        remotePc = new RTCPeerConnection();

        // Add tracks to local PC
        combinedStream.getTracks().forEach(track => {
          localPc.addTrack(track, combinedStream);
        });

        // Handle ICE candidates
        localPc.onicecandidate = (e) => {
          if (e.candidate) remotePc.addIceCandidate(e.candidate);
        };
        remotePc.onicecandidate = (e) => {
          if (e.candidate) localPc.addIceCandidate(e.candidate);
        };

        // Handle remote stream
        const remoteStream = new MediaStream();
        remotePc.ontrack = (e) => {
          remoteStream.addTrack(e.track);
          document.getElementById('remoteVideo').srcObject = remoteStream;
          log(`Remote track received: ${e.track.kind}`);
        };

        // Create offer/answer
        const offer = await localPc.createOffer();
        await localPc.setLocalDescription(offer);
        await remotePc.setRemoteDescription(offer);

        const answer = await remotePc.createAnswer();
        await remotePc.setLocalDescription(answer);
        await localPc.setRemoteDescription(answer);

        log('WebRTC signaling complete, waiting for connection...');

        // Wait for connection and check stats
        await new Promise(resolve => setTimeout(resolve, 2000));

        // Get WebRTC stats
        const stats = await remotePc.getStats();
        let videoPackets = 0, audioPackets = 0;

        stats.forEach(report => {
          if (report.type === 'inbound-rtp') {
            if (report.kind === 'video') {
              videoPackets = report.packetsReceived || 0;
            } else if (report.kind === 'audio') {
              audioPackets = report.packetsReceived || 0;
            }
          }
        });

        log(`WebRTC stats - Video packets: ${videoPackets}, Audio packets: ${audioPackets}`);

        // Test 6: Video
        if (videoPackets > 0) {
          testResults.webrtcVideoWorking = true;
          setTestStatus(6, 'pass', `${videoPackets} packets received`);
          log('WebRTC video loopback working', 'success');
        } else {
          setTestStatus(6, 'fail', 'No video packets');
          log('WebRTC video loopback failed - no packets', 'error');
        }

        // Test 7: Audio
        if (audioPackets > 0) {
          testResults.webrtcAudioWorking = true;
          setTestStatus(7, 'pass', `${audioPackets} packets received`);
          log('WebRTC audio loopback working', 'success');
        } else {
          setTestStatus(7, 'fail', 'No audio packets');
          log('WebRTC audio loopback failed - no packets', 'error');
        }

      } catch (error) {
        log(`Error: ${error.message}`, 'error');
        console.error(error);
      }

      // =====================================================
      // Final Result
      // =====================================================
      const allPassed = Object.values(testResults).every(v => v === true);
      const overallEl = document.getElementById('overallResult');

      if (allPassed) {
        overallEl.className = 'overall-result pass';
        overallEl.textContent = 'ALL TESTS PASSED';
        log('=== ALL TESTS PASSED ===', 'success');
      } else {
        overallEl.className = 'overall-result fail';
        const passedCount = Object.values(testResults).filter(v => v).length;
        overallEl.textContent = `${passedCount}/7 TESTS PASSED`;
        log(`=== ${passedCount}/7 TESTS PASSED ===`, 'error');
      }

      // Print summary
      log('');
      log('Test Summary:');
      log(`  Edge Window Found: ${testResults.edgeWindowFound ? 'PASS' : 'FAIL'}`);
      log(`  Video Capture: ${testResults.videoCaptureWorking ? 'PASS' : 'FAIL'}`);
      log(`  Audio Session Found: ${testResults.audioSessionFound ? 'PASS' : 'FAIL'}`);
      log(`  Audio Capture: ${testResults.audioCaptureWorking ? 'PASS' : 'FAIL'}`);
      log(`  Audio Level Detected: ${testResults.audioLevelDetected ? 'PASS' : 'FAIL'}`);
      log(`  WebRTC Video: ${testResults.webrtcVideoWorking ? 'PASS' : 'FAIL'}`);
      log(`  WebRTC Audio: ${testResults.webrtcAudioWorking ? 'PASS' : 'FAIL'}`);

      // Write results to file for verification
      try {
        const fs = require('fs');
        const path = require('path');
        const resultsFile = path.join(__dirname, 'test-results.json');
        const results = {
          timestamp: new Date().toISOString(),
          allPassed: allPassed,
          tests: testResults,
          audioLevel: maxAudioLevel
        };
        fs.writeFileSync(resultsFile, JSON.stringify(results, null, 2));
        log(`Results written to ${resultsFile}`, 'success');
      } catch (e) {
        log(`Failed to write results file: ${e.message}`, 'error');
      }
    }

    // Start tests when page loads
    window.addEventListener('DOMContentLoaded', () => {
      // Small delay to ensure preload is ready
      setTimeout(runTests, 500);
    });
  </script>
</body>
</html>
